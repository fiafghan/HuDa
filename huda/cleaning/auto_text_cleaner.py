import polars as pl
import re

def auto_text_cleaner(df, columns=None):
    """
    ğŸ§¹ Clean Text Fields in Dataset (Lowercase + Punctuation Removal)
    =================================================================

    ğŸ’¡ Simple Explanation:
    ----------------------
    This function automatically cleans text-type (string) columns in your dataset.
    It removes punctuation, converts text to lowercase, and trims extra spaces.

    ğŸ‘‡ What it does:
    ----------------
    - Changes all text to lowercase (for uniformity)
    - Removes punctuation marks (.,!? etc.)
    - Removes extra spaces or invisible characters
    - Works for English, Dari, and Pashto mixed datasets

    ğŸ§© Parameters:
    ---------------
    df : pl.DataFrame
        The dataset you want to clean
    columns : str | list[str] | None
        - None â†’ all string columns are cleaned automatically
        - str  â†’ clean only one column
        - list â†’ clean specific columns

    ğŸ§  Example Usage:
    -----------------
    import polars as pl

    df = pl.DataFrame({
        "respondent_name": ["  Ahmad!", "FATIMA,", "ZAHRA ", "Dr. Habib??"],
        "district": ["Kabul ", "  Herat", "Kandahar!", "Balkh."],
        "feedback": ["Good Service!", "   BAD ", "Ù…ØªÙˆØ³Ø·", " Ø¹Ø§Ù„ÛŒ "]
    })

    # ğŸ§¹ Clean all text fields automatically
    df_clean = clean_text_fields(df)

    print(df_clean)

    ğŸ§¾ Output:
    -----------
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ respondent_name  â”† district  â”† feedback     â”‚
    â”‚ ---              â”† ---       â”† ---          â”‚
    â”‚ str              â”† str       â”† str          â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ ahmad            â”† kabul     â”† good service â”‚
    â”‚ fatima           â”† herat     â”† bad          â”‚
    â”‚ zahra            â”† kandahar  â”† Ù…ØªÙˆØ³Ø·         â”‚
    â”‚ dr habib         â”† balkh     â”† Ø¹Ø§Ù„ÛŒ          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“… When & Why:
    -----------------
    âœ… Use when:
        - You have survey text fields with mixed punctuation
        - Texts are written in mixed languages or cases
        - You want to prepare text data for machine learning or analysis

    ğŸ’¡ Why:
        - Makes analysis consistent
        - Avoids duplication due to casing (e.g., â€œYesâ€ vs â€œyesâ€)
        - Removes unnecessary characters for cleaner processing
    """

    try:
        # âœ… Step 1: Auto-detect text columns
        if columns is None:
            columns_to_clean = [c for c, t in zip(df.columns, df.dtypes) if t == pl.Utf8]
        elif isinstance(columns, str):
            columns_to_clean = [columns]
        elif isinstance(columns, list):
            columns_to_clean = [c for c in columns if c in df.columns]
        else:
            raise ValueError("âŒ 'columns' must be str, list, or None")

        if not columns_to_clean:
            print("âš ï¸ No text columns found to clean.")
            return df

        # âœ… Step 2: Define cleaning function
        def clean_text(text):
            if text is None:
                return None
            # Remove punctuation and normalize spaces
            text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", str(text))  # keep Persian/Arabic letters
            text = re.sub(r"\s+", " ", text).strip().lower()
            return text

        # âœ… Step 3: Apply cleaning to selected columns
        for col in columns_to_clean:
            df = df.with_columns(
                pl.col(col).map_elements(clean_text, return_dtype=pl.Utf8)
            )

        print(f"âœ… Text cleaned successfully in columns: {', '.join(columns_to_clean)}")
        return df

    except Exception as e:
        print("âš ï¸ Error while cleaning text fields:", e)
        return df

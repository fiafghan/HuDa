import polars as pl

def duplicate(df, columns=None, keep="first"):
    """
    â™»ï¸ Handle (remove or keep) duplicate rows in a DataFrame.

    Parameters
    ----------
    df : pl.DataFrame
        The input DataFrame.
    columns : str | list[str] | None
        Columns to check for duplicates.
        - None â†’ check all columns.
        - str â†’ check only one column.
        - list[str] â†’ check based on multiple columns.
    keep : {"first", "last", False}
        - "first" â†’ keep the first occurrence.
        - "last" â†’ keep the last occurrence.
        - False â†’ remove all duplicates completely.

    Example:
    ----------
        import polars as pl
        from huda.cleaning.duplicate import duplicate

        df = pl.DataFrame({
            "country": ["Afghanistan", "Afghanistan", "Syria", "Yemen", "Yemen"],
            "year": [2025, 2025, 2024, 2025, 2025],
            "sector": ["Health", "Health", "Food", "Health", "Health"]
        })

        # âœ… Remove duplicates based on all columns
        df_no_dupes = duplicate(df)

        # âœ… Remove duplicates only based on one column
        df_country = duplicate(df, columns="country", keep="last")

        # âœ… Remove duplicates based on multiple columns
        df_multi = duplicate(df, columns=["country", "year"])

    Output Example:
    ----------
        shape: (3, 3)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ country      â”† year â”† sector â”‚
        â”‚ ---          â”† ---  â”† ---    â”‚
        â”‚ str          â”† i64  â”† str    â”‚
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
        â”‚ Afghanistan  â”† 2025 â”† Health â”‚
        â”‚ Syria        â”† 2024 â”† Food   â”‚
        â”‚ Yemen        â”† 2025 â”† Health â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    When and Why:
    -------------
    - ğŸ” When combining datasets from multiple sources, duplicates often appear.
    - ğŸ§¹ Removing them ensures cleaner and more accurate analysis.
    - ğŸ’¡ Always inspect your data before removing duplicates to avoid losing valid records.
    """
    try:
        # ğŸ”¹ Normalize column input (single str â†’ list)
        if isinstance(columns, str):
            columns = [columns]

        # ğŸ”¹ Handle duplicates
        df_clean = df.unique(subset=columns, keep=keep)

        if columns is None:
            print("âœ… Duplicates handled based on all columns.")
        else:
            print(f"âœ… Duplicates handled based on columns: {columns}")

        return df_clean

    except Exception as e:
        print("âš ï¸ Error while handling duplicates:", e)
        return df
